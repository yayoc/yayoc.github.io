---
layout: post
title:  "文字列をベクター化して、類義語を抽出してみる"
date:   2016-05-23 09:09:53 +0900
categories: python, synonym
---

とあるサービスを運営していて、単語のデータセットから特定単語の同義語を抽出する必要があったので、
bag of wordsの考え方を元にグリッド距離を算出して、
類義語を抽出するスクリプトを書いてみた。

## やること
* 文字列のベクター化　
* Stemmerを利用して、頻出単語の除去
* TF_IDFの利用
* 正規化したベクターを比較してユーグリッド距離を算出

## 用意するもの
下記のようなサンプルデータを用意する

1.txt
```
```
2.txt
```
```
3.txt
```
```
4.txt
```
```

5.txt
```
```

## スクリプト

{% highlight python %}

from sklearn.feature_extraction.text import CountVectorizer
import os
import scipy as sp
import sys
import nltk.stem

# Using TF_IDF ( term frequency - inverse document frequency )
# Not just counting words, TF-IDF let consider number of showing the word in other doucments.
english_stemmer = nltk.stem.SnowballStemmer('english')
from sklearn.feature_extraction.text import TfidfVectorizer
class StemmedTfidfVectorizer(TfidfVectorizer):
  def build_analyzer(self):
    analyzer = super(TfidfVectorizer, self).build_analyzer()
    return lambda doc: (
      english_stemmer.stem(w) for w in analyzer(doc)
    )

# Vectorize all of words data.
vectorizer = StemmedTfidfVectorizer(min_df=1, stop_words='english')
x_train = vectorizer.fit_transform(train_words)
num_samples, num_features = x_train.shape
print("#samples: %d, #features: %d" % (num_samples, num_features))

# Define new word
if (len(sys.argv) != 2):
  print("You should pass word id")
  sys.exit()
new_word_id = sys.argv[1]
new_word = db.words.find_one({'_id': ObjectId(new_word_id)})
new_word_data = create_train_data(new_word)
new_word_vec = vectorizer.transform([new_word_data])

# Getting Euclid  distance by comparing vectors which are normalized
def dist_norm(v1, v2):
  v1_normalized = v1/sp.linalg.norm(v1.toarray())
  v2_normalized = v2/sp.linalg.norm(v2.toarray())
  delta = v1_normalized - v2_normalized
  return sp.linalg.norm(delta.toarray())

class RelatedWord:
  def __init__(self, id, word, distance):
    self.id = id
    self.word = word
    self.distance = distance
  def __repr__(self):
    return repr((self.word, self.distance))

number_of_related_words = 3
def insert_if_needed(related_words, new_word):
  if len(related_words) < number_of_related_words:
    related_words.append(new_word)
    # print(related_words)
    return sorted(related_words, key=lambda w: w.distance)
  related_words.append(new_word)
  related_words = sorted(related_words, key=lambda w: w.distance)
  del related_words[-1]
  return related_words

# In this case, this script
related_words = []
for i in range(0, num_samples):
  word = train_words[i]
  if word == new_word_data:
    continue
  post_vec = x_train.getrow(i)
  d = dist_norm(post_vec, new_word_vec)
  db_word = db_words[i]
  related_word = RelatedWord(db_word['_id'], word, d)
  related_words = insert_if_needed(related_words, related_word)
print("new word: %s"%(new_word_id))
# Save words into relationships table.
for word in related_words:
  print(word.id)

{% endhighlight %}

P.S. 
ちなみにこのプラグインを使って、僕はしっかり[Tortoise](http://www.songkick.com/artists/136413-tortoise)のライブチケットを購入しました

